{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day 1  \n",
    "简介tensorflow  \n",
    "tensorflow的两个主要特点：python和data flow graph  \n",
    "data flow graph由node和edge组成：其中每一个运算操作将作为一个节点（node)，节点与节点之间的连接成为边(edge)，而在计算图的边中流动（flow）的数据被称为张量（tensor）  \n",
    "node的定义不仅包含加减乘除数学运算，还包含数据的定义与赋值 \n",
    "node包含的函数需要总结一下\n",
    "一个完整的tensorflow代码流程是：第一构建数据流图，第二个是像图中喂数据并且运行这个图，第三是更新数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_6:0\", shape=(), dtype=int32) Tensor(\"Const_7:0\", shape=(), dtype=int32) Tensor(\"add_6:0\", shape=(), dtype=int32)\n",
      "3 4 7\n"
     ]
    }
   ],
   "source": [
    "#构造一个简单的节点图\n",
    "node1 = tf.constant(3)\n",
    "node2 = tf.constant(4)\n",
    "#node3 = tf.add(node1, node2)\n",
    "node3 = node1+node2\n",
    "print(node1, node2, node3)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(node1), sess.run(node2), sess.run(node3))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析一下上面这个代码好像很简单，node1和node2直接都定义了常量，所以第二步都没有喂数据的操作了  \n",
    "那么怎么喂数据呢，用到了placeholder函数，这个函数可以不直接赋值，而是只定义一个类型的常量  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "[ 8. 10.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = tf.add(a,b)\n",
    "#added_node = a + b\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(adder_node, feed_dict={a:3, b:4}))\n",
    "print(sess.run(adder_node, feed_dict={a:[3,4], b:[5,6]}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对于上面这串代码，需要解释的一些事情：  \n",
    "sess.run后面的feed_dict即为喂数据的过程，用到了字典的数据结构    \n",
    "这串代码只讲到了第二步，并没有讲到第三步更新的过程，请继续看下面的内容  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor张量的使用：ranks，shapes，types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 机器学习中的回归问题：Regression\n",
    "我没有学过机器学习，但是我明白机器学习中的问题可以分成回归问题和分类问题classification  \n",
    "回归问题是说输入一个x根据某种函数关系输出一个y作为结果，类似于数学中的函数  \n",
    "分类问题是说输入一个x，输出值y必须是哪个类别中，本节主要讲回归问题  \n",
    "回归问题还有线性回归linear regression和逻辑回归logistic regression  \n",
    "线性回归问题是说函数是一个线性函数  \n",
    "逻辑回归问题可以等同于一个二分类问题binary classification  \n",
    "关于深度学习的流程这里就不再讲了，遇到的太多了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.848175 [-0.55155146] [-0.39593995]\n",
      "200 0.0031584913 [0.9347267] [0.14838156]\n",
      "400 0.0012060605 [0.9596651] [0.09169072]\n",
      "600 0.00046053375 [0.97507554] [0.05665923]\n",
      "800 0.00017585447 [0.98459816] [0.03501199]\n",
      "1000 6.7150184e-05 [0.9904827] [0.02163524]\n",
      "1200 2.5640853e-05 [0.99411887] [0.01336923]\n",
      "1400 9.791085e-06 [0.9963658] [0.00826138]\n",
      "1600 3.7388802e-06 [0.9977543] [0.00510503]\n",
      "1800 1.4277624e-06 [0.99861217] [0.00315476]\n",
      "2000 5.453351e-07 [0.99914235] [0.00194957]\n"
     ]
    }
   ],
   "source": [
    "##这是一个有关于线性回归的例子\n",
    "#首先定义训练数据\n",
    "xtrain = [1,2,3]\n",
    "#xtrain = tf.constant([1,2,3])\n",
    "ytrain = [1,2,3]\n",
    "#ytrain = tf.constant([1,2,3])\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weights')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "yhat = W * xtrain + b\n",
    "\n",
    "#定义损失函数\n",
    "cost = tf.reduce_mean(tf.square(yhat - ytrain))\n",
    "\n",
    "#定义更新用到的优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)#这不是一个节点\n",
    "train = optimizer.minimize(cost)#这是一个节点\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())#如果用到了变量的话，首先要进行初始化\n",
    "for step in range(0,2001):\n",
    "    sess.run(train)\n",
    "    if step % 200 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的代码是用到placeholder函数的一个代码，实现的功能是一样的，推荐使用这种格式的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.9515423 [-0.13793728] [1.4071238] None\n",
      "200 0.14062706 [0.5655047] [0.9877099] None\n",
      "400 0.05369823 [0.73150843] [0.6103445] None\n",
      "600 0.020504592 [0.8340886] [0.3771556] None\n",
      "800 0.007829673 [0.89747673] [0.23305947] None\n",
      "1000 0.0029897525 [0.9366469] [0.14401646] None\n",
      "1200 0.0011416245 [0.9608517] [0.08899333] None\n",
      "1400 0.00043593245 [0.9758087] [0.05499251] None\n",
      "1600 0.00016645981 [0.98505133] [0.03398196] None\n",
      "1800 6.356277e-05 [0.99076253] [0.02099888] None\n",
      "2000 2.4271401e-05 [0.9942919] [0.01297592] None\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weights')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "yhat = W * X + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(yhat - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)#这不是一个节点\n",
    "train = optimizer.minimize(cost)#这是一个节点\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())#如果用到了变量的话，首先要进行初始化\n",
    "for step in range(0,2001):\n",
    "    costv, wb, bb, _ = sess.run([cost, W, b, train], feed_dict={X:[1,2,3], Y:[1,2,3]})\n",
    "    if step % 200 == 0:\n",
    "        print(step, costv, wb, bb, _)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归进化成逻辑回归，逻辑回归和二分类算法就是一回事  \n",
    "区别在于第一加了sigmoid函数  \n",
    "第二cost function变了  \n",
    "第三在于分类问题可以计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.2937405\n",
      "200 0.34612426\n",
      "400 0.33473352\n",
      "600 0.32434997\n",
      "800 0.31470126\n",
      "1000 0.30563888\n",
      "1200 0.2970738\n",
      "1400 0.28894818\n",
      "1600 0.2812211\n",
      "1800 0.2738612\n",
      "2000 0.2668428\n",
      "\n",
      "Hypothesis:  [[0.09280091]\n",
      " [0.20391244]\n",
      " [0.51900274]\n",
      " [0.6943514 ]\n",
      " [0.8712237 ]\n",
      " [0.9599401 ]] \n",
      "predicted:  [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "accuracy:  0.8333333\n"
     ]
    }
   ],
   "source": [
    "#首先准备好训练的数据\n",
    "xdata = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "ydata = [[0], [0], [0], [1], [1], [1]]\n",
    "\n",
    "#定义训练数据\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name = 'weights')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')\n",
    "yhat = tf.sigmoid(tf.matmul(X,W) + b)\n",
    "\n",
    "#损失函数\n",
    "cost = -tf.reduce_mean(Y*tf.log(yhat) + (1-Y)*tf.log(1-yhat))\n",
    "\n",
    "#定义优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)#这不是一个节点\n",
    "train = optimizer.minimize(cost)#这是一个节点\n",
    "\n",
    "#准确率计算\n",
    "predicted = tf.cast(yhat>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "#训练过程\n",
    "#用with就不用执行sess.close()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        costv, _ = sess.run([cost, train], feed_dict={X:xdata, Y:ydata})\n",
    "        if step%200 == 0:\n",
    "            print(step, costv)\n",
    "            \n",
    "    #准确率计算\n",
    "    h, c, a = sess.run([yhat, predicted, accuracy], feed_dict={X:xdata, Y:ydata})\n",
    "    print(\"\\nHypothesis: \", h, \"\\npredicted: \", c, \"\\naccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里还涉及到了txt文件和csv文件处理的过程，暂且先不看了  \n",
    "向下继续softmax多分类问题  \n",
    "二分类问题转化成多分类问题的区别有\n",
    "第一把sigmoid函数转成softmax函数，由此损失函数也会改变  \n",
    "第二由此，损失函数，精确度计算都会改变  \n",
    "第三引入了一种新的向量表现形式one-hot向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.1551704\n",
      "200 1.0536641\n",
      "400 0.8915047\n",
      "600 0.7880783\n",
      "800 0.7162498\n",
      "1000 0.6643934\n",
      "1200 0.6253356\n",
      "1400 0.5946878\n",
      "1600 0.56976074\n",
      "1800 0.5488662\n",
      "2000 0.53091156\n"
     ]
    }
   ],
   "source": [
    "#首先准备好训练的数据\n",
    "xdata = [[1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], [1,7,5,5], [1,2,5,6], [1,6,6,6],[1,7,7,7]]\n",
    "ydata = [[0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], [0,1,0],[1,0,0],[1,0,0]]\n",
    "\n",
    "#定义训练数据\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "classnum = 3\n",
    "W = tf.Variable(tf.random_normal([4, classnum]), name = 'weights')\n",
    "b = tf.Variable(tf.random_normal([classnum]), name = 'bias')\n",
    "yhat = tf.nn.softmax(tf.matmul(X,W) + b)\n",
    "\n",
    "#损失函数\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(yhat), axis=1))\n",
    "\n",
    "#定义优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)#这不是一个节点\n",
    "train = optimizer.minimize(cost)#这是一个节点\n",
    "\n",
    "#准确率计算\n",
    "#predicted = tf.cast(yhat>0.5, dtype=tf.float32)\n",
    "#accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "#训练过程\n",
    "#用with就不用执行sess.close()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        costv, _ = sess.run([cost, train], feed_dict={X:xdata, Y:ydata})\n",
    "        if step%200 == 0:\n",
    "            print(step, costv)\n",
    "            \n",
    "    #准确率计算\n",
    "    #h, c, a = sess.run([yhat, predicted, accuracy], feed_dict={X:xdata, Y:ydata})\n",
    "    #print(\"\\nHypothesis: \", h, \"\\npredicted: \", c, \"\\naccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist训练集完整代码，用到softmax，这个之后有时间我会做一下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面是深度神经网络，也是用到了mnist数据集训练一个多分类器，比起之前的变化是网络编程多层的了  \n",
    "课后作业1：kaggle上titanic的例子：https://github.com/hunkim/KaggleZeroToAll/tree/master/k0-01-titanic\n",
    "课后作业2：tensor向量操作熟悉需要翻墙：https://docs.google.com/presentation/d/1gQ7Xxrhylkr5Kk5pG15yvX3yOln_hk2-H6jrQeXqKmU/edit#slide=id.g1d46586425_0_44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day1.5\n",
    "主要介绍DNN深度神经网络，单层的网络可能不能完成一些问题，这个时候就要用到深层网路发挥作用了  \n",
    "第一个例子是XOR的例子，单层的神经网络结构不能用，只能用到多层的神经网络 \n",
    "这个例子暂且不写了，没什么新的东西  \n",
    "多层神经网络与单层不同，主要是backpropogation上面，用到链式法则chain rule  \n",
    "第二是讲到了梯度爆炸的问题，解决方法是换激活函数，现在已经很少用到sigmoid函数了，而是用ReLu函数来代替  \n",
    "第三个讲到了过拟合的问题，判断的标准是训练集的准确度高而测试集的准确度不高，  \n",
    "解决的办法是三个，更大的数据集/减少特征维数/正则化，  \n",
    "正则化中包含了一个dropout  \n",
    "所以代码上面又需要补充一个dropout的语句，再补充一个batch的语句"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后是tensorboard的一个安装和使用步骤，这是我想要的，但是没有讲怎么安转啊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day2\n",
    "歇了三天了，重新拾起来看一看  \n",
    "回顾一下吧\n",
    "tf分为三步：\n",
    "第一步：定义常量变量，原始网络，损失函数，如果需要正则化也要进行正则化操作，需要dropout层也要在此定义  \n",
    "第二步：定义优化器，定义sess会话，初始化变量，运行会话，运行会话的时候可能用到batch操作  \n",
    "    插播一条，优化器有些什么？ tf.train.GradientDescentOptimizer/tf.train.AdamOptimizer/tf.train.MomentumOptimizer/tf.train.RMSpropOptimizer  \n",
    "第三步：更新变量，代码上虽然没有体现  \n",
    "除了这三步以外，还要定义评价函数，等到会话运行的时候一并运行起来  \n",
    "  \n",
    "今天要学习的是卷积神经网络  \n",
    "卷积的原理在这里就不讲了，注意两个术语就行了stride/padding：valid padding + same padding  \n",
    "卷积后面跟着激活函数  \n",
    "没了，day3暂且不用学了，day3讲的是rnn  \n",
    "后面就是实践了，要尽快拿一个网络来好好训练剖析一下  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day3\n",
    "实践专场，本来打算直接上手ResNet，但是老师并没有写相关代码，  \n",
    "先来实践一下mnist数据集  \n",
    "暂且学习一点基础处理语言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解释一下上面import的包  \n",
    "前两个包tensorflow和numpy不用说了  \n",
    "matplotlib是一个专门处理图像的包，和opencv，Image包都可以互相替换  \n",
    "mnist包是tensorflow专门写的关于这个数据集的处理语言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0224 19:45:45.170009 140446017124096 deprecation.py:323] From <ipython-input-2-663c3e077182>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0224 19:45:45.172298 140446017124096 deprecation.py:323] From /home/laptop2/lanenet1/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0224 19:45:45.173645 140446017124096 deprecation.py:323] From /home/laptop2/lanenet1/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0224 19:45:45.475644 140446017124096 deprecation.py:323] From /home/laptop2/lanenet1/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0224 19:45:45.478733 140446017124096 deprecation.py:323] From /home/laptop2/lanenet1/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0224 19:45:45.537153 140446017124096 deprecation.py:323] From /home/laptop2/lanenet1/venv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "#看不太懂这行代码，不过应该是读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb967f8550>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#显示出一张图像，对一张图像的处理，不知道为什么必须要处理一下图片的大小\n",
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "(1, 14, 14, 5) Tensor(\"Conv2D:0\", shape=(1, 14, 14, 5), dtype=float32)\n",
      "(1, 14, 14, 5)\n",
      "(5, 14, 14, 1)\n",
      "(14, 14, 1)\n",
      "(14, 14, 1)\n",
      "(14, 14, 1)\n",
      "(14, 14, 1)\n",
      "(14, 14, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb9435ebe0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = img.reshape(-1,28,28,1)\n",
    "print(img.shape)\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,5],stddev=0.01))\n",
    "#解释一下这行代码，这行是定义卷积核5个3*3*1的卷积核，后面的是标准差0.01\n",
    "conv2d = tf.nn.conv2d(img, W1, strides = [1,2,2,1], padding = 'SAME')\n",
    "print(conv2d.shape,conv2d)\n",
    "#input : 输入要做卷积的图片，要求为一个张量，[ batch, in_height, in_weight, in_channel ]，\n",
    "#filter：卷积核，要求也是一个张量，[ filter_height, filter_weight, in_channel, out_channels ]，\n",
    "#strides： 卷积时在图像每一维的步长，[ 1, strides, strides, 1]，第一位和最后一位固定必须是1\n",
    "#padding： \"SAME\"是考虑边界，不足的时候用0去填充周围，\"VALID\"则不考虑\n",
    "#use_cudnn_on_gpu： bool类型，是否使用cudnn加速，默认为true\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    conv2d_img = conv2d.eval()\n",
    "    print(conv2d_img.shape)\n",
    "#eval()这个函数是对conv2d这个张量估值，在tf中，张量的值是打印不出来的，如果要打印就要用到这个函数吧\n",
    "#为什么开了session之后才能运行这个函数，没开会话之前节点里面是没有填值的，不能运行\n",
    "    conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "    #维度对换操作\n",
    "    print(conv2d_img.shape)\n",
    "    for i, one_img in enumerate(conv2d_img):\n",
    "        print(one_img.shape)\n",
    "        plt.subplot(1,5,i+1)\n",
    "        plt.imshow(one_img.reshape(14,14), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_1:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAABcCAYAAABOZ1+dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAACY5JREFUeJzt3V2IVfUax/HfM5M6aTPRy8ygqUNHrJMh0qEXoi46gpUXIVFEdhUEduOFYog3RUSQ0NWBDqUcvCnC6sJKCau7XiB0rCP51kHNRodKJZ05kTo6PefC8bibtff/v2bWXnvvf34/IM7ez3L9H3/sedizZq29zN0FAEhHW7MbAABMDIMbABLD4AaAxDC4ASAxDG4ASAyDGwASw+AGgMQwuAEgMQxuAEjMVWXs1MyuiMsx3d3ybnulZCLppLt359mQTLI6Ojq8s7Oz7H6a7uTJk7kzkaSuri7v7s69eZJOnDih4eHhXDMl1+A2s4cl/UNSu6R/ufv6Av39aZjZdyKT8TrN7KDIpNKpvK+Vzs5OPfbYY43rrEk2bNiQOxNJ6u7u1vr1f+6X07p163JvGz1UYmbtkv4paamkBZKWm9mCSXf350ImWf8RmYw3V7xW/u/333+XyKSQPMe475Z00N0Pu/uIpM2SlpXbVhrIpKoRMsk4x2vlsuPHj0tkUkiewX2TpKMVj4+NPfcHZrbCzPrNrL9ezSWETLLI5LKRiq8zuVRmcvbs2cZ21gS//fabFMlE+mMuw8PDjWovCXU7q8TdN7r7ne5+Z732mToyySKTrMpMOjo6mt1Oy6jMpaurq9nttJQ8g3tQ0pyKx7PHnsNlZJJFJpdNrfj6is9l+vTpEpkUkmdw75Q038xuNrOpkp6U9GG5baWBTKqaSiYZHbxWLuvp6ZHIpJDo6YDufsHMVkr6WBdP3dnk7nuLLHrdddcV+eeSpNiPlHPmzAnWd+zYUbgHTSCTq6++WrfeemvN+lNPPRVdrK+vL1hvb28P1t96661g/f3334/2kMMtkvYrRybTpk3T7Nmza9Zvv/326GJz584N1r/66qtgfewMh5q+/vrraA85DKiO3z9FzZo1K1iPfX/u3Vus/ba2NmmCmUyZMkUzZ86sWb/qqviZzUePHg3We3t7g/Wff/45ukaj5DqP290/kvRRyb0kx91vaXYPLWgPx68zhsgkg0wK4JJ3AEgMgxsAEsPgBoDEMLgBIDEMbgBIDIMbABLD4AaAxJRyI4UFCxbonXfeqVnP80HxN9xwQ7B+6tSpYP3w4cPB+sqVK6M97NmzJ7pNXn19fXr99ddr1mMXB+TpZ8aMGcH6Qw89FKzv3Lkz2sPgYP2uTO7t7dXatWtr1kdHR6P7+Omnn4L12IVNq1evDtbNct8roy7a29t1zTXX1Ky/9tpr0X3cdttthXpYs2ZNsL5sWfyD/D744INCPYw3ffp0LVq0qGY9z2eZPPfcc4V6ePXVV4P19957r9D+J4J33ACQGAY3ACSGwQ0AiWFwA0BiGNwAkBgGNwAkhsENAIkp5Tzuffv2aeHChYX2ce211wbrZ86cCdZPnz4drD/yyCPRHup5HveBAwd07733FtrHpk2bgvX77rsvWI/dfGL9+vUT7qmIgYEBPfvss4X2sWLFimB9//79wfr8+fMLrV9vo6Oj+vXXX2vWn3766cJr3HHHHcH6888/H6x///330TXqfR730NCQtm/fXrP+7rvvRvdx/fXXB+u//PJLsD52y7WaPv/882gPsetL8uIdNwAkhsENAIlhcANAYhjcAJAYBjcAJIbBDQCJYXADQGJKOY87ZsOGDdFtHnjggWB95syZwfr58+eD9SVLlkR7eOWVV6Lb1MvWrVuj2/T09ATrzzzzTLAe+/8MDAxEe2ikPK+TXbt2BevTpk0L1mfNmjWhnprt0KFD0W0WL14crH/zzTfB+pEjR4L1l19+OdpDo8XOwZakl156KVh/4YUXgvVVq1YF6/U6RzsP3nEDQGIY3ACQGAY3ACSGwQ0AiWFwA0BiGNwAkBgGNwAkpinncX/xxRfRbWKf0zxlypRgfWRkJFhfu3ZttIdGevTRR6PbXLhwIVjfsWNHsH7XXXcF6+4e7aGRtm3bFt0mdv77448/HqyfPXt2Qj0127x586Lb/PDDD4XWePHFF4P1Y8eOFdp/GWLXdUjx87Rj3njjjWB98+bN0X0MDQ0V6uGSXIPbzI5I+q+kUUkX3P3OuqyeODP7VmQy3kJyySCTLDIpYCLvuP/u7idL6yRNZFIduWSRSRaZTBLHuAEgMXkHt0v6xMx2mVnVm/yZ2Qoz6zez/vq11/LIpLqauZBJOJPUjrkXlPv7Z3h4uNG9tbS8h0rud/dBM+uR9KmZHXD3zyo3cPeNkjZKkpm11m+5SuLufyOTjAOhXMgknEl3dzeZjKnMZd68eVdKLrnkesft7oNjfx+XtEXS3WU2lRIyyTgvkcs4ZJJFJgVEB7eZzTCzzktfS3pQ0p6yG0sFmWS0SeQyDplUGPvIZTIpIM+hkl5JW8zs0vZvu/v2UrtKhJntFpmM91dyySCTCmfOnJHIpJDo4Hb3w5IW1XPRN998s/A+li5dGqzv3r07WO/vL/67MXevWy6xi2vy+PLLL4P1e+65p/AaOeyr1zm5eW4uEfPEE08E68uXLy+8Rg51y6QeYhda/fjjj6Wu39XVJdU5k3PnzhXeR1tb+ABE7MYe9bq4Jg9OBwSAxDC4ASAxDG4ASAyDGwASw+AGgMQwuAEgMQxuAEiMlfHh+WZ2QlLlp7nfKKnVP75xoj32uXt33o2vkEykCeRCJllVMpnsmo3G909WaZmUMrgzi5j1t9IFCNU0ukcyaf56k9GMHsml+etNRpk9cqgEABLD4AaAxDRqcG9s0DpFNLpHMmn+epPRjB7JpfnrTUZpPTbkGDcAoH44VAIAiSl1cJvZw2b2nZkdNLN1Za5VhJkdMbNvzezfZd8LkUxqrtfyuZBJFplUV3ou7l7KH0ntkg5J+oukqZJ2S1pQ1noFez0i6cYGrEMmCedCJmTSKrmU+Y77bkkH3f2wu49I2ixpWYnrpYBMqiOXLDLJIpMxZQ7umyQdrXh8bOy5VuSSPjGzXWa2osR1yKS6VHIhkywyqa7UXPLcc/JKcL+7D5pZj6RPzeyAu3/W7KaajEyyyCSLTKorNZcy33EPSppT8Xj22HMtx90Hx/4+LmmLLv5IVgYyqS6JXMgki0yqKzuXMgf3TknzzexmM5sq6UlJH5a43qSY2Qwz67z0taQHJe0paTkyqa7lcyGTLDKprhG5lHaoxN0vmNlKSR/r4m+DN7n73rLWK6BX0hYzky7m8ba7by9jITKpLpFcyCSLTKorPReunASAxHDlJAAkhsENAIlhcANAYhjcAJAYBjcAJIbBDQCJYXADQGIY3ACQmP8BgvFOEc2J0WQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb91fe4198>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[\n",
    "                        1, 2, 2, 1], padding='SAME')\n",
    "print(pool)\n",
    "#解析池化函数\n",
    "#value：需要池化的输入，一般接在卷积层后面，通常是feature map，[batch, height, width, channels]\n",
    "#ksize：池化窗口的大小，取一个四维向量，一般是[1, height, width, 1]\n",
    "#strides：和卷积类似，窗口在每一个维度上滑动的步长，一般也是[1, stride,stride, 1]\n",
    "#padding：和卷积类似，可以取'VALID' 或者'SAME'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    pool_img = pool.eval()\n",
    "    pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "    for i, one_img in enumerate(pool_img):\n",
    "        plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "关于真正去运行一个代码，见下一个文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
